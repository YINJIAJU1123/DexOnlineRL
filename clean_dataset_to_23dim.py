import pandas as pd
import numpy as np
import json
import os
import shutil
import glob

# ================= é…ç½®åŒº =================
# 1. ä½ çš„åŸå§‹æ•°æ®é›†è·¯å¾„ (26ç»´)
INPUT_DIR = "/home/lixin/OnlineRl/experiments/revoarm_bottle/offline_dataset/revoarm_bottle_23"  # è¿™é‡Œå¡«ä½ åŸæœ¬26ç»´çš„é‚£ä¸ªæ–‡ä»¶å¤¹

# 2. æ–°æ•°æ®é›†è¾“å‡ºè·¯å¾„ (23ç»´)
OUTPUT_DIR = "/home/lixin/OnlineRl/experiments/revoarm_bottle/offline_dataset/revoarm_bottle_cleaned_23dim"

# 3. ç›®æ ‡ç»´åº¦
TARGET_DIM = 23
# ==========================================

def clean_dataset():
    if os.path.exists(OUTPUT_DIR):
        print(f"âš ï¸ è¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼Œå»ºè®®åˆ é™¤æˆ–æ”¹å: {OUTPUT_DIR}")
        return
    os.makedirs(OUTPUT_DIR)
    
    print(f"ğŸš€ å¼€å§‹æ•°æ®æ¸…æ´—: 26ç»´ -> {TARGET_DIM}ç»´")

    # === 1. å¤åˆ¶ meta æ–‡ä»¶å¤¹ (é™¤äº†æˆ‘ä»¬è¦æ”¹çš„æ–‡ä»¶) ===
    src_meta = os.path.join(INPUT_DIR, "meta")
    dst_meta = os.path.join(OUTPUT_DIR, "meta")
    os.makedirs(dst_meta, exist_ok=True)
    
    # === 2. æ¸…æ´— info.json ===
    print("Processing info.json...")
    with open(os.path.join(src_meta, "info.json"), 'r') as f:
        info = json.load(f)
    
    # ä¿®æ”¹ shape å’Œ names
    for key in ['observation.state', 'action']:
        if key in info['features']:
            info['features'][key]['shape'] = [TARGET_DIM]
            # åªä¿ç•™å‰ 23 ä¸ªåå­—
            old_names = info['features'][key]['names']
            if old_names and len(old_names) >= TARGET_DIM:
                info['features'][key]['names'] = old_names[:TARGET_DIM]
    
    with open(os.path.join(dst_meta, "info.json"), 'w') as f:
        json.dump(info, f, indent=4)

    # === 3. æ¸…æ´— stats.json ===
    print("Processing stats.json...")
    with open(os.path.join(src_meta, "stats.json"), 'r') as f:
        stats = json.load(f)

    # é€’å½’å¤„ç†æ‰€æœ‰åˆ—è¡¨ï¼Œæˆªæ–­åˆ° 23
    def recursive_slice(d):
        for k, v in d.items():
            if isinstance(v, dict):
                recursive_slice(v)
            elif isinstance(v, list):
                # åªæœ‰é•¿åº¦ >= 26 çš„åˆ—è¡¨æ‰åˆ‡ï¼Œé˜²æ­¢åˆ‡é”™ï¼ˆæ¯”å¦‚ timestamp è¿™ç§é•¿åº¦ä¸º1çš„ï¼‰
                if len(v) >= 26: 
                    d[k] = v[:TARGET_DIM]

    recursive_slice(stats)
    
    with open(os.path.join(dst_meta, "stats.json"), 'w') as f:
        json.dump(stats, f, indent=4)
        
    # === 4. å¤åˆ¶ videos æ–‡ä»¶å¤¹ (ç›´æ¥ç¡¬é“¾æ¥æˆ–å¤åˆ¶) ===
    print("Linking videos...")
    src_videos = os.path.join(INPUT_DIR, "videos")
    dst_videos = os.path.join(OUTPUT_DIR, "videos")
    if os.path.exists(src_videos):
        shutil.copytree(src_videos, dst_videos) # è§†é¢‘ä¸ç”¨æ”¹

    # === 5. æ ¸å¿ƒï¼šæ¸…æ´— Parquet æ•°æ® ===
    print("Processing Parquet files...")
    data_files = glob.glob(os.path.join(INPUT_DIR, "data/chunk-*/episode_*.parquet"))
    
    for file_path in data_files:
        # æ„å»ºè¾“å‡ºè·¯å¾„
        rel_path = os.path.relpath(file_path, INPUT_DIR)
        out_path = os.path.join(OUTPUT_DIR, rel_path)
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        
        # è¯»å–
        df = pd.read_parquet(file_path)
        
        # å¤„ç† State
        if 'observation.state' in df.columns:
            # æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ª numpy array æˆ– listï¼Œæˆ‘ä»¬éœ€è¦åˆ‡ç‰‡
            df['observation.state'] = df['observation.state'].apply(
                lambda x: x[:TARGET_DIM] if len(x) >= TARGET_DIM else x
            )
            
        # å¤„ç† Action
        if 'action' in df.columns:
            df['action'] = df['action'].apply(
                lambda x: x[:TARGET_DIM] if len(x) >= TARGET_DIM else x
            )
            
        # ä¿å­˜
        df.to_parquet(out_path)
        print(f"-> Saved: {rel_path}")

    # === 6. å¤åˆ¶ tasks.jsonl ===
    shutil.copy(os.path.join(src_meta, "tasks.jsonl"), os.path.join(dst_meta, "tasks.jsonl"))

    print("\nâœ… æ•°æ®æ¸…æ´—å®Œæˆï¼")
    print(f"æ–°çš„æ•°æ®é›†è·¯å¾„: {OUTPUT_DIR}")
    print("è¯·ä¿®æ”¹ configï¼Œå°† dataset_repo_id æŒ‡å‘è¿™ä¸ªæ–°è·¯å¾„ã€‚")

if __name__ == "__main__":
    # éœ€è¦å…ˆå®‰è£…ä¾èµ–: pip install pandas pyarrow
    clean_dataset()